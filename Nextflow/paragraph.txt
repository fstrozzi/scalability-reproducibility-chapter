Nextflow is a framework and an orchestration tool that enables scalable and reproducible scientific workflows using software containers. It provides a domain specific language (DSL) that simplifies the writing and the deployment of complex parallel and distributed workflows across different execution platforms in a portable manner.

A Nextflow pipeline is made up by putting together several processes. Each process can be written in any scripting language that can be executed by the Linux platform (BASH, Perl, Ruby, Python, etc). Parallelisation is automatically managed by the framework and it is implicitly defined by the processes input and output declarations.

A key component of Nextflow is the dataflow programming model. Dataflow is a declarative processing model for parallel task executions in which concurrency and synchronisation is managed automatically and tasks communicate by using asynchronous queues called channels.

It includes a rich set of functions common bioinformatics use cases including, for example, sequences file splitting, files searching and grouping by name, along with standard operators that allow the manipulations of data channels. 

Nextflow and the dataflow paradigm are based on a "push" concept. In this model the first process in the workflow will send its outputs over to the downstream processes that will wait for the data to arrive before starting their computation. Branches in the workflow are also entirely possible and easy to define using conditions that specify if certain processes must be executed or not depending on the data or on user defined parameters. 

It is the closest representation of a pipeline idea, where you open the valve at the beginning and watch the flow progressing through the pipes. But Nextflow can handle this dataflow in a parallel and asynchronous manner, so a process can operate on multiple inputs and emit multiple outputs at the same time. In a simple workflow where, for instance, there are 100 nucleotide sequences to be aligned with the NCBI NT database using BLAST, a first process can compute the alignment on the 100 sequences in parallel, while a second process will wait to receive and collect each of the outputs from the 100 alignments to create a final results file. 

Nextflow can run a workflow locally or using a computing cluster, in that case common schedulers like SLURM, PBS, LSF and SGE are supported, plus a built-in scheduler is also available based on Apache Ignite. Nextflow allows also to run workflows directly into the Amazon Web Services (AWS) cloud using managed services like AWS Batch or automating the creation of a computing cluster in the cloud for the user.

The built足in support for container technologies such as Docker and Singularity, along with the native integration with the Git tool and popular code足sharing platforms like GitHub, make it possible to precisely prototype self足contained computational workflows, maintain all variations over time and rapidly reproduce any former configuration one may need to re足use. These capabilities guarantee consistent results over time and across different computing platforms.

In order to run the Nextflow example you need to have Java 7 (or 8) and a Docker engine (1.10 or higher) installed in your computer, then to run the example the following command:

```
cd scalability-reproducibility-chapter/Nextflow
./nextflow run workflow.nf -with-docker springer/scalability
```

